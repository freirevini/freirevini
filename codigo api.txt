# -*- coding: utf-8 -*-
import os
import re
import json
import logging
import pathlib
import datetime as dt
from typing import List, Dict, Optional, Tuple

import win32com.client as win32
import pandas as pd
import requests
from bs4 import BeautifulSoup
from dateutil import parser as dtparser

# =========================
# CONFIG
# =========================
# Intervalo para buscar os e-mails na pasta alvo
DATA_INICIO = "01/03/2025"   # dd/mm/yyyy
DATA_FIM    = "07/03/2025"   # dd/mm/yyyy
# PRODUÇÃO (últimos 3 dias):
# _hoje = dt.datetime.today()
# DATA_INICIO, DATA_FIM = (_hoje - dt.timedelta(days=3)).strftime("%d/%m/%Y"), _hoje.strftime("%d/%m/%Y")

REMETENTE_FILTRO = "informe@mkcompliance.com.br"
ASSUNTO_FIXO = "[EXT] - Normativos Divulgados em "
OUTLOOK_FOLDER_PATH = r"Caixa de Entrada\Normas MK Compliance"

PASTA_DESTINO = r"N:\DCGV\Compliance\Compliance RO Varejo\Analytics\Projetos\AgendaNormativa\Normativo_Download_Outlook"
ARQUIVO_EXCEL_METAS  = r"N:\DCGV\Compliance\Compliance RO Varejo\Analytics\Projetos\AgendaNormativa\Melhorias_Agenda\3_BaseMK\BaseMkNormasParaAvaliar.xlsx"
STATE_JSON           = os.path.join(PASTA_DESTINO, "state.json")

HTTP_TIMEOUT = 45
LOG_LEVEL = logging.INFO
logging.basicConfig(level=LOG_LEVEL, format="%(asctime)s [%(levelname)s] %(message)s")

# =========================
# HELPERS (normalização, aliases, chave)
# =========================
def ensure_dir(path: str | pathlib.Path) -> None:
    pathlib.Path(path).mkdir(parents=True, exist_ok=True)

def N(txt: str) -> str:
    import unicodedata
    txt = str(txt or "")
    txt = "".join(c for c in unicodedata.normalize("NFKD", txt) if not unicodedata.combining(c))
    return re.sub(r"\s+", " ", txt.upper().strip())

def only_digits(s: str) -> str:
    return re.sub(r"\D", "", str(s or ""))

ALIASES_ORGAO_RAW = {
    "BANCO NACIONAL DE DESENVOLVIMENTO ECONOMICO E SOCIAL": ["BNDES"],
    "MINISTERIO DAS CIDADES": ["MCID", "MINISTERIO DA CIDADE"],
    "MINISTERIO DA FAZENDA": ["MF", "FAZENDA"],
    "MINISTERIO DA ECONOMIA": ["ME", "ECONOMIA"],
    "BANCO CENTRAL DO BRASIL": ["BCB", "BACEN", "BANCO CENTRAL"],
    "CONSELHO MONETARIO NACIONAL": ["CMN"]
}
ALIASES_ORGAO = {N(k): [N(v) for v in vs] for k, vs in ALIASES_ORGAO_RAW.items()}

def canon_orgao(s: str) -> str:
    sN = N(s)
    for key, aliases in ALIASES_ORGAO.items():
        if key in sN or sN in key or any(a in sN for a in aliases):
            return key
    return sN  # fallback: próprio normalizado

def tipo_main_token(s: str) -> str:
    t = N(s)
    return re.split(r"[^\w]+", t)[0] if t else ""

def build_key(orgao: str, tipo: str, numero: str) -> str:
    return f"{canon_orgao(orgao)}_{tipo_main_token(tipo)}_{only_digits(numero)}"

def sanitize_filename(s: str) -> str:
    s = re.sub(r"[^\w\-. ]", "_", s, flags=re.UNICODE)
    s = re.sub(r"\s+", "_", s)
    s = re.sub(r"_+", "_", s)
    return s.strip("._")[:180]

def filename_orgao_tipo_num(orgao: str, tipo: str, numero: str) -> str:
    base = f"{orgao}_{tipo}_{only_digits(numero)}"
    return sanitize_filename(base) + ".pdf"

def load_state() -> Dict:
    try:
        if os.path.exists(STATE_JSON):
            with open(STATE_JSON, "r", encoding="utf-8") as f:
                return json.load(f)
    except Exception:
        pass
    return {}

def save_state(state: Dict) -> None:
    ensure_dir(os.path.dirname(STATE_JSON))
    with open(STATE_JSON, "w", encoding="utf-8") as f:
        json.dump(state, f, ensure_ascii=False, indent=2)

def state_has_key(state: Dict, key_norm: str) -> bool:
    return key_norm in state.setdefault("downloaded_keys", [])

def state_add_key(state: Dict, key_norm: str) -> None:
    arr = state.setdefault("downloaded_keys", [])
    if key_norm not in arr:
        arr.append(key_norm)

def file_already_present(dest_dir: str, base_filename: str) -> Optional[str]:
    stem = os.path.splitext(base_filename)[0].lower()
    for f in os.listdir(dest_dir):
        if f.lower().endswith(".pdf") and f.lower().startswith(stem):
            return os.path.join(dest_dir, f)
    return None

# =========================
# Outlook – abrir pasta e filtrar e-mails
# =========================
def open_outlook_folder_by_path(path_str: str):
    ns = win32.Dispatch("Outlook.Application").GetNamespace("MAPI")
    parts = [p for p in path_str.split("\\") if p.strip()]
    if not parts:
        return ns.GetDefaultFolder(6)

    root = None
    first = parts[0]
    for i in range(1, ns.Folders.Count + 1):
        store = ns.Folders.Item(i)
        if str(store.Name).strip().lower() == first.strip().lower():
            root = store
            parts = parts[1:]
            break

    if root is None:
        root = ns.GetDefaultFolder(6)
        if first.strip().lower() in ["inbox", "caixa de entrada"]:
            parts = parts[1:]

    folder = root
    for p in parts:
        folder = folder.Folders.Item(p)
    return folder

def restrict_by_date_and_subject(items, di: dt.datetime, df_: dt.datetime) -> list:
    di_s = di.strftime("%m/%d/%Y")
    df_s = df_.strftime("%m/%d/%Y")
    filtro = f"[ReceivedTime] >= '{di_s} 00:00 AM' AND [ReceivedTime] <= '{df_s} 11:59 PM'"
    candidates = list(items.Restrict(filtro))
    out = []
    for mail in candidates:
        try:
            subj = str(getattr(mail, "Subject", "") or "")
            from_addr = str(getattr(mail, "SenderEmailAddress", "") or "")
            if REMETENTE_FILTRO.lower() not in from_addr.lower():
                continue
            if not subj.startswith(ASSUNTO_FIXO):
                continue
            # garante que a data do assunto está no range
            data_str = subj.replace(ASSUNTO_FIXO, "").strip()
            try:
                d_ass = dt.datetime.strptime(data_str, "%d/%m/%Y")
            except Exception:
                continue
            if di <= d_ass <= df_:
                out.append(mail)
        except Exception:
            continue
    return out

# =========================
# Extrair tabela (Tipo, Número, Órgão) do corpo do e-mail
# =========================
COLS_CANON = ["Tipo", "Número", "Órgão"]

HEADER_VARIANTS = {
    "Órgão": {N("Órgão"), N("Órgão regulador"), N("Orgao"), N("Orgao Regulador"), N("Orgão Regulador")},
    "Tipo": {N("Tipo"), N("Tipo da Norma"), N("Espécie"), N("Especie")},
    "Número": {N("Número"), N("Numero"), N("Nº"), N("No"), N("N."), N("N")},
}

FORWARD_MARKERS = re.compile(
    r"(mensagem encaminhada|encaminhada|enc:|fw:|forwarded message|-----+ original message -----+)",
    re.I
)

def _row_cells(tr) -> list[str]:
    tds = tr.find_all(["td", "th"])
    return [td.get_text(" ", strip=True) for td in tds]

def _header_mapping(cells_norm: list[str]) -> Dict[int, str]:
    idx_to_key = {}
    for i, txt in enumerate(cells_norm):
        for canon, variants in HEADER_VARIANTS.items():
            if txt in variants and canon not in idx_to_key.values():
                idx_to_key[i] = canon
                break
    return idx_to_key

def _scan_table_for_header(table) -> Optional[Tuple[Dict[int, str], int, list]]:
    trs = table.find_all("tr")
    if not trs:
        return None
    best = None
    for idx, tr in enumerate(trs):
        cells = _row_cells(tr)
        if not cells:
            continue
        cells_norm = [N(c) for c in cells]
        mapping = _header_mapping(cells_norm)
        keys = set(mapping.values())
        if ({"Tipo","Número","Órgão"} & keys) and ("Número" in keys):
            score = (len(keys),)
            if (best is None) or (score > best[0]):
                best = (score, mapping, idx, trs)
    if best is None:
        return None
    _, mapping, idx, trs = best
    return mapping, idx, trs

def extract_email_table(html: str) -> pd.DataFrame:
    """
    Retorna DataFrame com colunas: Tipo, Número, Órgão
    """
    if not html:
        return pd.DataFrame(columns=COLS_CANON)

    cut_html = html
    m = FORWARD_MARKERS.search(html)
    if m:
        cut_html = html[:m.start()]

    soup = BeautifulSoup(cut_html, "lxml")
    for table in soup.find_all("table"):
        header_scan = _scan_table_for_header(table)
        if not header_scan:
            continue
        idx_to_key, idx_header, trs = header_scan

        rows = []
        for tr in trs[idx_header+1:]:
            cells = _row_cells(tr)
            if not cells:
                continue
            row = {k: "" for k in COLS_CANON}
            for i, canon in idx_to_key.items():
                if i < len(cells) and canon in COLS_CANON:
                    row[canon] = cells[i]
            if only_digits(row.get("Número", "")):
                rows.append(row)

        if rows:
            df = pd.DataFrame(rows, columns=COLS_CANON)
            for c in COLS_CANON:
                df[c] = df[c].fillna("").astype(str).str.replace("\xa0", " ", regex=False).str.strip()
            return df

    return pd.DataFrame(columns=COLS_CANON)

# =========================
# Metas (Excel): Órgão regulador, Tipo, Número  -> DataFrame
# =========================
def load_metas(path: str) -> pd.DataFrame:
    df = pd.read_excel(path, dtype=str).fillna("")
    # Garante nomes e ordem pedidas
    expected = ["Órgão regulador", "Tipo", "Número"]
    missing = [c for c in expected if c not in df.columns]
    if missing:
        raise RuntimeError(f"Colunas faltando na planilha de metas: {missing}")
    # cria chave
    out = df.copy()
    out["CHAVE"] = out.apply(lambda r: build_key(r["Órgão regulador"], r["Tipo"], r["Número"]), axis=1)
    out["PDF"] = ""
    out["Caminho"] = ""
    return out

# =========================
# Anexos / download
# =========================
def score_attachment(filename: str, orgao: str, tipo: str, numero: str) -> int:
    nameN = N(filename)
    score = 0
    if only_digits(numero) and only_digits(numero) in nameN:
        score += 100
    tok = tipo_main_token(tipo)
    if tok and tok in nameN:
        score += 20
    if canon_orgao(orgao) in nameN:
        score += 10
    for alias in ALIASES_ORGAO.get(canon_orgao(orgao), []):
        if alias in nameN:
            score += 10
    return score

def all_pdf_attachments(mail) -> List[Tuple[str, object]]:
    out = []
    try:
        cnt = int(getattr(mail.Attachments, "Count", 0))
        for i in range(1, cnt + 1):
            att = mail.Attachments.Item(i)
            name = str(getattr(att, "FileName", "") or "")
            if name.lower().endswith(".pdf"):
                out.append((name, att))
    except Exception as e:
        logging.warning(f"Erro ao ler anexos: {e}")
    return out

def find_pdf_links(html: str, numero: str) -> List[str]:
    links = []
    if not html:
        return links
    soup = BeautifulSoup(html, "lxml")
    nd = only_digits(numero)
    for a in soup.find_all("a"):
        href = (a.get("href") or "").strip()
        if href.lower().endswith(".pdf") and (nd in N(href)):
            links.append(href)
    return links

def download_link(url: str, dest: str) -> bool:
    try:
        r = requests.get(url, timeout=HTTP_TIMEOUT, allow_redirects=True)
        if r.status_code >= 400:
            return False
        with open(dest, "wb") as f:
            f.write(r.content)
        return True
    except Exception:
        return False

# =========================
# PIPELINE
# =========================
def main():
    ensure_dir(PASTA_DESTINO)
    state = load_state()

    # 1) importar as duas tabelas (DATAFRAMES)
    metas_df = load_metas(ARQUIVO_EXCEL_METAS)  # colunas originais + CHAVE/PDF/Caminho
    logging.info(f"Metas: {len(metas_df)} linhas")

    folder = open_outlook_folder_by_path(OUTLOOK_FOLDER_PATH)
    items = folder.Items
    items.Sort("[ReceivedTime]", True)
    di = dt.datetime.strptime(DATA_INICIO, "%d/%m/%Y")
    df_ = dt.datetime.strptime(DATA_FIM, "%d/%m/%Y")
    mails = restrict_by_date_and_subject(items, di, df_)
    logging.info(f"E-mails elegíveis: {len(mails)}")

    email_tables = []
    mail_by_id = {}
    for mail in mails:
        entry_id = str(getattr(mail, "EntryID", ""))
        html = str(getattr(mail, "HTMLBody", "") or "")
        df_email = extract_email_table(html)     # -> Tipo, Número, Órgão
        if df_email.empty:
            continue
        # 2) construir CHAVE para a tabela do e-mail
        df_email["CHAVE"] = df_email.apply(lambda r: build_key(r["Órgão"], r["Tipo"], r["Número"]), axis=1)
        df_email["EMAIL_ENTRY_ID"] = entry_id
        email_tables.append(df_email)
        mail_by_id[entry_id] = mail

    if not email_tables:
        logging.warning("Nenhuma tabela válida extraída dos e-mails.")
        # Mesmo sem e-mails, geramos o Excel final (sem PDFs marcados)
        out_excel = os.path.join(os.path.dirname(ARQUIVO_EXCEL_METAS),
                                 pathlib.Path(ARQUIVO_EXCEL_METAS).stem + "_com_PDF.xlsx")
        metas_df.to_excel(out_excel, index=False)
        logging.info(f"Planilha gerada: {out_excel}")
        return

    emails_df = pd.concat(email_tables, ignore_index=True)

    # 3) MATCH por CHAVE (Órgão + Tipo + Número), usando os dois DataFrames
    matches = emails_df.merge(metas_df[["CHAVE","Órgão regulador","Tipo","Número"]],
                              on="CHAVE", how="inner")
    if matches.empty:
        logging.info("Nenhum match por CHAVE encontrado.")
        out_excel = os.path.join(os.path.dirname(ARQUIVO_EXCEL_METAS),
                                 pathlib.Path(ARQUIVO_EXCEL_METAS).stem + "_com_PDF.xlsx")
        metas_df.to_excel(out_excel, index=False)
        logging.info(f"Planilha gerada: {out_excel}")
        return

    logging.info(f"Matches por CHAVE: {len(matches)}")

    # 4) download — 1 PDF por CHAVE
    for key, grp in matches.groupby("CHAVE"):
        idx_metas = metas_df.index[metas_df["CHAVE"] == key]
        if idx_metas.empty:
            continue

        orgao = metas_df.loc[idx_metas[0], "Órgão regulador"]
        tipo  = metas_df.loc[idx_metas[0], "Tipo"]
        numero= metas_df.loc[idx_metas[0], "Número"]

        base_name = filename_orgao_tipo_num(orgao, tipo, numero)
        already = file_already_present(PASTA_DESTINO, base_name)
        if state_has_key(state, N(key)) or already:
            metas_df.loc[idx_metas, "PDF"] = "SIM"
            metas_df.loc[idx_metas, "Caminho"] = already or os.path.join(PASTA_DESTINO, base_name)
            continue

        # tentar pelo e-mail mais recente primeiro
        grp_sorted = grp.iloc[::-1]  # não temos data aqui; reverte só para variar
        saved_path = ""
        for _, r in grp_sorted.iterrows():
            mail = mail_by_id.get(r["EMAIL_ENTRY_ID"])
            if mail is None:
                continue
            atts = all_pdf_attachments(mail)

            # escolher melhor anexo por score (número/tipo/órgão)
            scored = []
            for name, att in atts:
                sc = score_attachment(name, orgao, tipo, numero)
                if sc >= 100:  # exige número no nome do PDF
                    scored.append((sc, name, att))
            scored.sort(reverse=True)

            if scored:
                _, name, att = scored[0]
                dest = os.path.join(PASTA_DESTINO, base_name)
                k = 1
                while os.path.exists(dest):
                    dest = os.path.join(PASTA_DESTINO,
                                        sanitize_filename(os.path.splitext(base_name)[0] + f"_{k}.pdf"))
                    k += 1
                att.SaveAsFile(dest)
                saved_path = dest
                break

            # fallback: link com número no corpo
            html = str(getattr(mail, "HTMLBody", "") or "")
            for url in find_pdf_links(html, numero):
                dest = os.path.join(PASTA_DESTINO, base_name)
                k = 1
                while os.path.exists(dest):
                    dest = os.path.join(PASTA_DESTINO,
                                        sanitize_filename(os.path.splitext(base_name)[0] + f"_{k}.pdf"))
                    k += 1
                if download_link(url, dest):
                    saved_path = dest
                    break
            if saved_path:
                break

        if saved_path:
            metas_df.loc[idx_metas, "PDF"] = "SIM"
            metas_df.loc[idx_metas, "Caminho"] = saved_path
            state_add_key(state, N(key))

    # 5) gerar apenas o Excel final com PDF/Caminho (no mesmo lugar da metas)
    out_excel = os.path.join(os.path.dirname(ARQUIVO_EXCEL_METAS),
                             pathlib.Path(ARQUIVO_EXCEL_METAS).stem + "_com_PDF.xlsx")
    # ordem: colunas originais + PDF + Caminho
    metas_df[["Órgão regulador","Tipo","Número","PDF","Caminho"]].to_excel(out_excel, index=False)
    save_state(state)
    logging.info(f"Planilha gerada: {out_excel}")

# =========================
# RUN
# =========================
if __name__ == "__main__":
    main()
