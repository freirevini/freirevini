"""
norma_coletor.py
=================

Este módulo implementa uma forma de buscar e extrair o texto
completo de normas publicadas no Diário Oficial da União (DOU) a partir de
informações básicas do ato normativo: órgão regulador, tipo, número e data
de publicação.

A estratégia adotada consiste em:

1. Consultar o mecanismo de busca do DOU para localizar a página da
   publicação oficial com base nos termos fornecidos (tipo, número e órgão).
2. Abrir a página da matéria e capturar o link para o PDF oficial através
   do endpoint ``INPDFViewer`` que a Imprensa Nacional utiliza para
   disponibilizar os documentos.
3. Baixar o PDF com uma sessão ``requests`` configurada e extrair o texto
   integral usando ``PyPDF2``. Caso a extração falhe em alguma página,
   simplesmente retorna uma string vazia para aquela página.

Para usar este módulo você precisa instalar as seguintes dependências:

```
pip install requests beautifulsoup4 PyPDF2 pandas
```

Exemplo de uso:

.. code-block:: python

    from norma_coletor import coletar_normas

    parametros = [
        {
            "orgao": "Banco Central do Brasil",
            "tipo": "Resolução BCB",
            "numero": "277",
            "data": "2022-12-31",
        },
        {
            "orgao": "Conselho Monetário Nacional",
            "tipo": "Resolução CMN",
            "numero": "4958",
            "data": "2021-11-25",
        },
    ]
    df = coletar_normas(parametros)
    print(df[["órgão regulador", "tipo", "numero", "Texto completo da norma"]].head())

``coletar_normas`` retornará um ``pandas.DataFrame`` contendo, além
dos campos fornecidos, o texto completo da norma e o link do PDF de
origem. Caso não seja possível localizar a norma ou baixar o documento,
esses campos aparecerão como ``None``.
"""

import io
import re
from dataclasses import dataclass
from typing import List, Dict, Optional

import pandas as pd  # type: ignore
import requests
from bs4 import BeautifulSoup  # type: ignore
from urllib.parse import urljoin

# Tentamos importar bibliotecas de extração de PDF. Se nenhuma delas
# estiver instalada, a extração de texto será desativada (texto retorna ``None``).
try:
    from PyPDF2 import PdfReader  # type: ignore

    def _extract_text_from_pdf_bytes_impl(pdf_bytes: bytes) -> str:
        """Extrai texto de PDF utilizando PyPDF2.

        Percorre todas as páginas retornando o texto concatenado. Caso
        ocorra alguma falha em uma página específica, ignora e segue.
        """
        reader = PdfReader(io.BytesIO(pdf_bytes))
        texts: List[str] = []
        for page in reader.pages:
            try:
                txt = page.extract_text()
            except Exception:
                txt = ""
            if txt:
                texts.append(txt)
        return "\n".join(texts)
except Exception:
    try:
        # Tenta utilizar pdfminer.six como fallback
        from pdfminer.high_level import extract_text  # type: ignore

        def _extract_text_from_pdf_bytes_impl(pdf_bytes: bytes) -> str:
            """Extrai texto de PDF utilizando pdfminer.six.

            A função escreve os bytes em um ``BytesIO`` e usa o helper
            ``extract_text``. É mais lenta que PyPDF2, mas tolerante.
            """
            with io.BytesIO(pdf_bytes) as fp:
                return extract_text(fp) or ""
    except Exception:
        # Nenhuma biblioteca de PDF disponível
        def _extract_text_from_pdf_bytes_impl(pdf_bytes: bytes) -> str:
            return ""


class NormaColetor:
    """Classe responsável por pesquisar e extrair normas completas do DOU.

    A classe encapsula uma sessão HTTP com ``requests`` configurada com
    cabeçalhos adequados (``User-Agent`` e ``Accept-Language``) e oferece
    métodos auxiliares para busca no DOU, extração de links de PDF e
    download/extração do texto.
    """

    def __init__(self) -> None:
        # Configura a sessão para reutilizar conexões e incluir cabeçalhos
        self.session: requests.Session = requests.Session()
        self.session.headers.update({
            "User-Agent": "Mozilla/5.0 (NormaColetor/1.0; +https://example.org)",
            "Accept-Language": "pt-BR,pt;q=0.9,en;q=0.7",
        })

    def _search_dou(self, orgao: str, tipo: str, numero: str, data_publicacao: str) -> List[Dict[str, str]]:
        """Busca na página de consulta do DOU pelas normas informadas.

        Os parâmetros são concatenados em uma consulta entre aspas para
        aumentar a precisão do buscador. A função retorna uma lista de
        dicionários contendo o título e a URL de cada resultado.
        """
        query = f'"{tipo} {numero}" "{orgao}"'
        params = {
            "q": query,
            "s": "todos",
            "exactDate": data_publicacao,
            "sortType": "0",
            "page": "1",
        }
        url = "https://www.in.gov.br/consulta/-/buscar/dou"
        try:
            resp = self.session.get(url, params=params, timeout=30)
            resp.raise_for_status()
        except Exception:
            return []
        soup = BeautifulSoup(resp.text, "lxml")
        items: List[Dict[str, str]] = []
        for a in soup.select('a[href*="/web/dou/"], a[href*="/materia/-/"]'):
            href = a.get("href")
            title = a.get_text().strip()
            if not href:
                continue
            full_url = urljoin(url, href)
            items.append({"url": full_url, "title": title})
        # Remove duplicados preservando ordem
        seen: set = set()
        dedup: List[Dict[str, str]] = []
        for it in items:
            if it["url"] in seen:
                continue
            seen.add(it["url"])
            dedup.append(it)
        return dedup

    def _extract_pdf_url_from_article(self, article_url: str) -> Optional[str]:
        """Extrai o link para o PDF oficial a partir da página da matéria.

        A página de matérias do DOU contém, em seu HTML, um link para o
        serviço ``INPDFViewer``. Este método busca esse link e retorna a
        URL absoluta. Caso não encontre, retorna ``None``.
        """
        try:
            resp = self.session.get(article_url, timeout=30)
            # se a página retornar erro, aborta
            if resp.status_code >= 400:
                return None
            # Procura por um link contendo "INPDFViewer"
            m = re.search(r'href="([^"]*INPDFViewer[^"]*)"', resp.text)
            if m:
                pdf_url = urljoin(article_url, m.group(1))
                return pdf_url
        except Exception:
            return None
        return None

    def _download_pdf(self, pdf_url: str) -> Optional[bytes]:
        """Baixa o PDF indicado pelo link.

        Retorna o conteúdo binário do PDF ou ``None`` em caso de erro.
        """
        try:
            resp = self.session.get(pdf_url, timeout=60)
            resp.raise_for_status()
            return resp.content
        except Exception:
            return None

    def _extract_text_from_pdf_bytes(self, pdf_bytes: bytes) -> str:
        """Extrai texto de um PDF a partir de seu conteúdo em bytes.

        Se uma biblioteca de extração estiver disponível (PyPDF2 ou
        pdfminer.six), ela será utilizada. Caso contrário, retorna uma
        string vazia, indicando que o texto não pôde ser extraído.
        """
        return _extract_text_from_pdf_bytes_impl(pdf_bytes)

    def _find_pdf_url(self, orgao: str, tipo: str, numero: str, data: str) -> Optional[str]:
        """Executa a busca e retorna o primeiro link de PDF encontrado.

        A função prioriza resultados cujo título contenha explicitamente o
        número da norma. Caso não encontre, tenta o primeiro resultado
        retornado.
        """
        hits = self._search_dou(orgao, tipo, numero, data)
        pdf_url: Optional[str] = None
        for h in hits:
            if str(numero).lower() in h["title"].lower():
                pdf_url = self._extract_pdf_url_from_article(h["url"])
                if pdf_url:
                    break
        if not pdf_url and hits:
            pdf_url = self._extract_pdf_url_from_article(hits[0]["url"])
        return pdf_url

    def coletar_norma(self, orgao: str, tipo: str, numero: str, data: str) -> Dict[str, Optional[str]]:
        """Pesquisa uma norma e retorna metadados e texto completo.

        Os parâmetros correspondem à ementa da norma. O retorno é um
        dicionário contendo todos os campos solicitados na tabela:

        - ``órgão regulador``
        - ``tipo``
        - ``numero``
        - ``data de publicação``
        - ``Texto completo da norma``
        - ``fonte_pdf`` (link para o PDF)
        """
        pdf_url = self._find_pdf_url(orgao, tipo, numero, data)
        full_text: Optional[str] = None
        if pdf_url:
            pdf_bytes = self._download_pdf(pdf_url)
            if pdf_bytes:
                try:
                    full_text = self._extract_text_from_pdf_bytes(pdf_bytes)
                except Exception:
                    # Falha ao extrair texto; mantém None
                    full_text = None
        return {
            "órgão regulador": orgao,
            "tipo": tipo,
            "numero": numero,
            "data de publicação": data,
            "Texto completo da norma": full_text,
            "fonte_pdf": pdf_url,
        }


def coletar_normas(lista_parametros: List[Dict[str, str]]) -> pd.DataFrame:
    """Coleta uma lista de normas e retorna um DataFrame com os resultados.

    ``lista_parametros`` deve conter dicionários com as chaves ``orgao``,
    ``tipo``, ``numero`` e ``data`` (no formato YYYY-MM-DD). O retorno
    é um DataFrame com as colunas especificadas na requisição.
    """
    coletor = NormaColetor()
    linhas: List[Dict[str, Optional[str]]] = []
    for params in lista_parametros:
        linhas.append(coletor.coletar_norma(
            orgao=params.get("orgao", ""),
            tipo=params.get("tipo", ""),
            numero=params.get("numero", ""),
            data=params.get("data", ""),
        ))
    return pd.DataFrame(linhas)


__all__ = ["NormaColetor", "coletar_normas"]